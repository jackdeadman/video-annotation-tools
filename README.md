# Video annotation tools
Annotation tools developed for the paper "Simulating realistically-spatialised simultaneous speech using video-driven speaker detection and the CHiME-5 dataset".

- [Tracking annotator](https://github.com/jackdeadman/tracking-annotator)
- Face annotator (Coming soon)

## Citation
If you find these tools useful for your research please cite the following paper:
```
@inproceedings{Deadman-Barker_2020,  
  author = {Deadman, Jack and Barker, Jon},
  title = {{Simulating realistically-spatialised simultaneous speech using video-driven speaker detection and the CHiME-5 dataset}},  
  year = 2020,  
  booktitle = {Proceedings of the 21st Annual Conference of the International Speech Communication Association (INTERSPEECH 2020)}  
}
```

The paper has been accepted for Interspeech2020 and will be presented in October. [Preprint](https://drive.google.com/file/d/13UFVDuFSXBJxAwwGYUGr5WdWspUy_RVf/view?usp=sharing)
